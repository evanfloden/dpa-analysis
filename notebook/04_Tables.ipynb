{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tables\n",
    "\n",
    "The tables generated below are used both as guide trees in the progressive\n",
    "alignment proceedure as well as trees used in the clustering step \n",
    "of the regressive alignment proceedure.\n",
    "\n",
    "\n",
    "The generated tables can be found in the `results/tables/` directory of this repository.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##########################\n",
    "# Import python packages #\n",
    "##########################\n",
    "\n",
    "import os\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################\n",
    "# Change directory relative to repository home #\n",
    "################################################\n",
    "\n",
    "pwd = os.getcwd()\n",
    "work_dir=pwd+\"/..\"\n",
    "os.chdir(work_dir)\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'seatoxin': '93', 'hip': '167', 'scorptoxin': '363', 'cyt3': '385', 'rnasemam': '498', 'bowman': '499', 'toxin': '508', 'ghf11': '521', 'TNF': '556', 'sti': '613', 'Stap_Strp_toxin': '640', 'profilin': '687', 'ricin': '747', 'ghf22': '760', 'ChtBD': '774', 'ins': '793', 'trfl': '837', 'slectin': '932', 'phoslip': '946', 'ltn': '1068', 'il8': '1073', 'az': '1086', 'kringle': '1091', 'cryst': '1160', 'DEATH': '1183', 'cah': '1379', 'mmp': '1427', 'rub': '1435', 'ghf10': '1502', 'tgfb': '1606', 'sodcu': '2038', 'KAS': '2070', 'DMRL_synthase': '2099', 'tms': '2118', 'GEL': '2195', 'kunitz': '2266', 'Sulfotransfer': '2489', 'mofe': '2567', 'Ald_Xan_dh_2': '2589', 'ghf5': '2717', 'phc': '2957', 'aadh': '3127', 'annexin': '3139', 'serpin': '3144', 'cytb': '3206', 'asp': '3262', 'oxidored_q6': '3348', 'hpr': '3349', 'hormone_rec': '3509', 'hr': '3707', 'tim': '3904', 'glob': '3983', 'ace': '3989', 'cys': '4316', 'ghf1': '4358', 'sodfe': '4455', 'peroxidase': '4514', 'uce': '4558', 'flav': '4612', 'HMG_box': '4779', 'OTCace': '4795', 'msb': '4884', 'icd': '5678', 'proteasome': '5732', 'cyclo': '6288', 'LIM': '6428', 'HLH': '6781', 'ldh': '7367', 'subt': '7517', 'int': '7572', 'lyase_1': '7632', 'gpdh': '7691', 'egf': '7774', 'blm': '9105', 'gluts': '10099', 'myb_DNA-binding': '10398', 'tRNA-synt_2b': '11293', 'biotin_lipoyl': '11833', 'hom': '12037', 'ghf13': '12607', 'aldosered': '13277', 'hla': '13465', 'Rhodanese': '14049', 'PDZ': '14950', 'blmb': '17200', 'rhv': '17976', 'p450': '21013', 'adh': '21331', 'aat': '25100', 'rrm': '27610', 'Acetyltransf': '46285', 'sdr': '50157', 'zf-CCHH': '88345', 'rvp': '93681'}\n"
     ]
    }
   ],
   "source": [
    "####################################################\n",
    "# Read in the number of sequences for each dataset #\n",
    "####################################################\n",
    "\n",
    "with open(\"data/num_seqs.csv\", mode='r') as infile:\n",
    "    reader = csv.reader(infile, delimiter='\\t')\n",
    "    sizes_dict = {rows[0]:rows[1] for rows in reader}\n",
    "    \n",
    "print(sizes_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#################################################\n",
    "# Function to read in accuracy and scores files #\n",
    "#################################################\n",
    "\n",
    "def scores_to_dict(scores_dir, scores_dict, tag):\n",
    "    scores_list=[]\n",
    "    for score_file in os.listdir(scores_dir):\n",
    "        family, align_type, bucket, aligner, tree, score_type = score_file.split('.')\n",
    "        y = tuple([tag, align_type, aligner, tree, family, score_type])\n",
    "        with open(scores_dir + score_file, 'r') as infile:\n",
    "            data = infile.read()\n",
    "        scores_dict[y]=data.rstrip()\n",
    "    return scores_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##################################################\n",
    "# Read in the full and reference datasets scores #\n",
    "##################################################\n",
    "\n",
    "scores_dict = {}\n",
    "full_scores_dir=\"results/individual_scores/\"\n",
    "scores_dict = scores_to_dict(full_scores_dir, scores_dict, \"full\")\n",
    "\n",
    "ref_scores_dir=\"results_reference/individual_scores/\"\n",
    "scores_dict = scores_to_dict(ref_scores_dir, scores_dict, \"ref\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['default_align', 'MAFFT-SPARSECORE', 'DEFAULT'] 53.504999999999995\n",
      "['dpa_align', 'MAFFT-SPARSECORE', 'MAFFT-FFTNS1'] 53.50500000000001\n",
      "['std_align', 'MAFFT-GINSI', 'MAFFT-FFTNS1'] 52.605\n",
      "['dpa_align', 'MAFFT-SPARSECORE', 'CLUSTALO'] 53.50500000000001\n",
      "['dpa_align', 'UPP', 'MAFFT_PARTTREE'] 49.90500000000001\n",
      "['dpa_align', 'MAFFT-FFTNS1', 'MAFFT-FFTNS1'] 47.989999999999995\n",
      "['dpa_align', 'MAFFT-SPARSECORE', 'MAFFT_PARTTREE'] 53.504999999999995\n",
      "['dpa_align', 'MAFFT-GINSI', 'MAFFT-FFTNS1'] 53.504999999999995\n",
      "['std_align', 'MAFFT-GINSI', 'CLUSTALO'] 53.06999999999999\n",
      "['std_align', 'MAFFT-FFTNS1', 'MAFFT-FFTNS1'] 47.99\n",
      "['dpa_align', 'CLUSTALO', 'MAFFT-FFTNS1'] 53.71\n",
      "['std_align', 'CLUSTALO', 'MAFFT-FFTNS1'] 50.53999999999999\n",
      "['dpa_align', 'UPP', 'CLUSTALO'] 49.89\n",
      "['std_align', 'MAFFT-GINSI', 'MAFFT_PARTTREE'] 49.459999999999994\n",
      "['default_align', 'UPP', 'DEFAULT'] 49.78000000000001\n",
      "['dpa_align', 'MAFFT-FFTNS1', 'CLUSTALO'] 47.99\n",
      "['dpa_align', 'UPP', 'MAFFT-FFTNS1'] 49.845\n",
      "['dpa_align', 'CLUSTALO', 'MAFFT_PARTTREE'] 53.709999999999994\n",
      "['dpa_align', 'MAFFT-GINSI', 'CLUSTALO'] 53.504999999999995\n",
      "['std_align', 'MAFFT-FFTNS1', 'CLUSTALO'] 52.029999999999994\n",
      "['std_align', 'CLUSTALO', 'CLUSTALO'] 53.71\n",
      "['dpa_align', 'MAFFT-FFTNS1', 'MAFFT_PARTTREE'] 47.99\n",
      "['std_align', 'MAFFT-FFTNS1', 'MAFFT_PARTTREE'] 47.839999999999996\n",
      "['dpa_align', 'CLUSTALO', 'CLUSTALO'] 53.710000000000015\n",
      "['dpa_align', 'MAFFT-GINSI', 'MAFFT_PARTTREE'] 53.50500000000001\n",
      "['std_align', 'CLUSTALO', 'MAFFT_PARTTREE'] 50.54\n"
     ]
    }
   ],
   "source": [
    "#################################################################################\n",
    "# Create a dictionary for average TC scores and CPU time when above 10,000 seqs #\n",
    "#################################################################################\n",
    "\n",
    "# Dictionary of the average TC scores and CPU time\n",
    "full_top20_tc_avg_dict={}\n",
    "ref_top20_tc_avg_dict={}\n",
    "cpu_top20_dict={}\n",
    "\n",
    "# Take all datasets and create a dictionary of average scores\n",
    "datasets=set([k[1]+'/'+k[2]+'/'+k[3] for k,v in scores_dict.items() ])\n",
    "\n",
    "# Calculate average TC score for each of the full datasets with over 10,000 sequences\n",
    "for dataset in datasets:\n",
    "    key = dataset.split(\"/\")\n",
    "    i = [v for k,v in scores_dict.items() if k[0]=='full' and k[1]==key[0] and k[2]==key[1] and k[3]==key[2] and int(sizes_dict[k[4]]) > 10000 and k[5]=='tc']\n",
    "    l = [float(j) for j in i]\n",
    "    if (len(l)==20):\n",
    "        avg = sum(l)/float(len(l))\n",
    "        full_top20_tc_avg_dict[tuple(key)]=avg\n",
    "\n",
    "# Calculate average TC for each of the reference datasets\n",
    "for dataset in datasets:\n",
    "    key = dataset.split(\"/\")\n",
    "    i = [v for k,v in scores_dict.items() if k[0]=='ref' and k[1]==key[0] and k[2]==key[1] and k[3]==key[2] and int(sizes_dict[k[4]]) > 10000 and k[5]=='tc']\n",
    "    l = [float(j) for j in i]\n",
    "    if (len(l)==20):\n",
    "        avg = sum(l)/float(len(l))\n",
    "        print(key, avg)\n",
    "        ref_top20_tc_avg_dict[tuple(key)]=avg\n",
    "\n",
    "# Calculate average CPU time required for each the datasets with over 10,000 sequences\n",
    "for dataset in datasets:\n",
    "    key = dataset.split(\"/\")\n",
    "    i = [v for k,v in scores_dict.items() if k[0]=='full' and k[1]==key[0] and k[2]==key[1] and k[3]==key[2] and int(sizes_dict[k[4]]) > 10000 and k[5]=='cpu']\n",
    "    l = [float(j) for j in i]\n",
    "    if (len(l)==20):\n",
    "        avg = sum(l)/float(len(l))\n",
    "        cpu_top20_dict[tuple(key)]=avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#########################\n",
    "# Export Table 1 as CSV #\n",
    "#########################\n",
    "\n",
    "with open('results/tables/table1.csv', 'w') as csvfile:\n",
    "    filewriter = csv.writer(csvfile, delimiter=',')\n",
    "\n",
    "    filewriter.writerow(['','','non-regressive','regressive','reference','non-regressive','regressive'])\n",
    "    filewriter.writerow(['tree method','alignment method','score %','score %','score %','cpu time (ms)','cpu time (ms)'])\n",
    "\n",
    "    f_dic, r_dic, cpu_dic, aligner, tree = full_top20_tc_avg_dict, ref_top20_tc_avg_dict, cpu_top20_dict, 'MAFFT-FFTNS1', 'MAFFT_PARTTREE'\n",
    "    filewriter.writerow(['parttree','fftns1',f_dic['std_align',aligner,tree],f_dic['dpa_align',aligner,tree],r_dic['std_align',aligner,tree],cpu_dic['std_align',aligner,tree],cpu_dic['dpa_align',aligner,tree]])\n",
    " \n",
    "    f_dic, r_dic, cpu_dic, aligner, tree = full_top20_tc_avg_dict, ref_top20_tc_avg_dict, cpu_top20_dict, 'MAFFT-FFTNS1', 'CLUSTALO'\n",
    "    filewriter.writerow(['mbed','fftns1',f_dic['std_align',aligner,tree],f_dic['dpa_align',aligner,tree],r_dic['std_align',aligner,tree],cpu_dic['std_align',aligner,tree],cpu_dic['dpa_align',aligner,tree]])\n",
    " \n",
    "    f_dic, r_dic, cpu_dic, aligner, tree = full_top20_tc_avg_dict, ref_top20_tc_avg_dict, cpu_top20_dict, 'CLUSTALO', 'MAFFT_PARTTREE'\n",
    "    filewriter.writerow(['parttree','clustalo',f_dic['std_align',aligner,tree],f_dic['dpa_align',aligner,tree],r_dic['std_align',aligner,tree],cpu_dic['std_align',aligner,tree],cpu_dic['dpa_align',aligner,tree]])\n",
    "\n",
    "    f_dic, r_dic, cpu_dic, aligner, tree = full_top20_tc_avg_dict, ref_top20_tc_avg_dict, cpu_top20_dict, 'CLUSTALO', 'CLUSTALO'\n",
    "    filewriter.writerow(['mbed','clustalo',f_dic['std_align',aligner,tree],f_dic['dpa_align',aligner,tree],r_dic['std_align',aligner,tree],cpu_dic['std_align',aligner,tree],cpu_dic['dpa_align',aligner,tree]])\n",
    "    \n",
    "    filewriter.writerow(['average','','','','','',''])\n",
    "    filewriter.writerow(['','','','','','',''])\n",
    "    \n",
    "    f_dic, r_dic, cpu_dic, aligner, tree = full_top20_tc_avg_dict, ref_top20_tc_avg_dict, cpu_top20_dict, 'UPP', 'DEFAULT'\n",
    "    filewriter.writerow(['default/mbed','upp',f_dic['default_align',aligner,tree],f_dic['dpa_align',aligner,'CLUSTALO'],r_dic['default_align',aligner,tree],cpu_dic['default_align',aligner,tree],cpu_dic['dpa_align',aligner,'CLUSTALO']])\n",
    " \n",
    "    f_dic, r_dic, cpu_dic, aligner, tree = full_top20_tc_avg_dict, ref_top20_tc_avg_dict, cpu_top20_dict, 'MAFFT-SPARSECORE', 'DEFAULT'\n",
    "    filewriter.writerow(['default/mbed','sparsecore',f_dic['default_align',aligner,tree],f_dic['dpa_align',aligner,'CLUSTALO'],r_dic['default_align',aligner,tree],cpu_dic['default_align',aligner,tree],cpu_dic['dpa_align',aligner,'CLUSTALO']])\n",
    " \n",
    "    f_dic, r_dic, cpu_dic, aligner, tree = full_top20_tc_avg_dict, ref_top20_tc_avg_dict, cpu_top20_dict, 'MAFFT-GINSI', 'MAFFT_PARTTREE'\n",
    "    filewriter.writerow(['parttree','ginsi','-',f_dic['dpa_align',aligner,tree],r_dic['std_align',aligner,tree],'-',cpu_dic['dpa_align',aligner,tree]])\n",
    "\n",
    "    f_dic, r_dic, cpu_dic, aligner, tree = full_top20_tc_avg_dict, ref_top20_tc_avg_dict, cpu_top20_dict, 'MAFFT-GINSI', 'CLUSTALO'\n",
    "    filewriter.writerow(['mbed','ginsi','-',f_dic['dpa_align',aligner,tree],r_dic['std_align',aligner,tree],'-',cpu_dic['dpa_align',aligner,tree]]) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#######################################\n",
    "# Export all raw results as CSV table #\n",
    "#######################################\n",
    "\n",
    "with open('results/tables/full_table_sp.csv', 'w') as csvfile:\n",
    "    filewriter = csv.writer(csvfile, delimiter=',')\n",
    "    for e in scores_dict:\n",
    "        if e[5] == 'sp':\n",
    "            filewriter.writerow([e[0], e[1], e[2], e[3], e[4], sizes_dict[e[4]], scores_dict[e]])\n",
    "            \n",
    "with open('results/tables/full_table_tc.csv', 'w') as csvfile:\n",
    "    filewriter = csv.writer(csvfile, delimiter=',')\n",
    "    for e in scores_dict:\n",
    "        if e[5] == 'tc':\n",
    "            filewriter.writerow([e[0], e[1], e[2], e[3], e[4], sizes_dict[e[4]], scores_dict[e]])\n",
    "\n",
    "with open('results/tables/full_table_cpu.csv', 'w') as csvfile:\n",
    "    filewriter = csv.writer(csvfile, delimiter=',')\n",
    "    for e in scores_dict:\n",
    "        if e[5] == 'cpu':\n",
    "            filewriter.writerow([e[0], e[1], e[2], e[3], e[4], sizes_dict[e[4]], scores_dict[e]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "########################\n",
    "# Export table for CCA #\n",
    "########################\n",
    "\n",
    "with open('results/tables/Constrained_Correspondence_Analysis.csv', 'w') as csvfile:\n",
    "    filewriter = csv.writer(csvfile, delimiter=',')\n",
    "    \n",
    "    f_dic = full_top20_tc_avg_dict\n",
    "    \n",
    "    filewriter.writerow(['reg_method','tree_method','align_method','accuracy'])\n",
    "    \n",
    "    filewriter.writerow(['non-reg','parttree','fft-ns-1',f_dic['std_align','MAFFT-FFTNS1','MAFFT_PARTTREE']])\n",
    "    filewriter.writerow(['non-reg','mBed','fft-ns-1',f_dic['std_align','MAFFT-FFTNS1','CLUSTALO']])\n",
    "    filewriter.writerow(['non-reg','partree','clustalo',f_dic['std_align','CLUSTALO','MAFFT_PARTTREE']])\n",
    "    filewriter.writerow(['non-reg','mBed','clustalo',f_dic['std_align','CLUSTALO','CLUSTALO']])\n",
    "    \n",
    "    filewriter.writerow(['non-reg','uppT','upp',f_dic['default_align','UPP','DEFAULT']])\n",
    "    filewriter.writerow(['non-reg','sparsecoreT','sparsecore',f_dic['default_align','MAFFT-SPARSECORE','DEFAULT']])\n",
    "    \n",
    "    filewriter.writerow(['reg','parttree','fft-ns-1',f_dic['dpa_align','MAFFT-FFTNS1','MAFFT_PARTTREE']])\n",
    "    filewriter.writerow(['reg','mBed','fft-ns-1',f_dic['dpa_align','MAFFT-FFTNS1','CLUSTALO']])\n",
    "    filewriter.writerow(['reg','parttree','clustalo',f_dic['dpa_align','CLUSTALO','MAFFT_PARTTREE']])\n",
    "    filewriter.writerow(['reg','mBed','clustalo',f_dic['dpa_align','CLUSTALO','CLUSTALO']])\n",
    "    \n",
    "    filewriter.writerow(['reg','mBed','upp',f_dic['dpa_align','UPP','CLUSTALO']])\n",
    "\n",
    "    filewriter.writerow(['reg','mBed','sparsecore',f_dic['dpa_align','MAFFT-SPARSECORE','CLUSTALO']])\n",
    "    filewriter.writerow(['reg','parttree','sparsecore',f_dic['dpa_align','MAFFT-SPARSECORE','MAFFT_PARTTREE']])\n",
    "    \n",
    "    filewriter.writerow(['reg','parttree','g-ins-1',f_dic['dpa_align','MAFFT-GINSI','MAFFT_PARTTREE']])\n",
    "    filewriter.writerow(['reg','mBed','g-ins-1',f_dic['dpa_align','MAFFT-GINSI','CLUSTALO']])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
